#!/usr/bin/env python3
"""
ì „ì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹(752ê°œ)ì—ì„œ ì£¼ìš” baseline ëª¨ë¸ë“¤ í‰ê°€
"""
import sys
import json
import numpy as np
from pathlib import Path
from typing import Dict, List, Any, Tuple
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import (
    GradientBoostingClassifier, RandomForestClassifier
)
try:
    from xgboost import XGBClassifier
    XGBOOST_AVAILABLE = True
except ImportError:
    XGBOOST_AVAILABLE = False

try:
    from lightgbm import LGBMClassifier
    LIGHTGBM_AVAILABLE = True
except ImportError:
    LIGHTGBM_AVAILABLE = False

try:
    from catboost import CatBoostClassifier
    CATBOOST_AVAILABLE = True
except ImportError:
    CATBOOST_AVAILABLE = False

from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import StackingClassifier, VotingClassifier, AdaBoostClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    roc_auc_score
)

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from core.scoring.stage1_scorer import Stage1Scorer
from scripts.improve_stage2_performance import extract_enhanced_features


def load_dataset(file_path: Path) -> Tuple[List[np.ndarray], List[int]]:
    """ë°ì´í„°ì…‹ ë¡œë“œ ë° feature ì¶”ì¶œ"""
    with open(file_path, 'r') as f:
        data = json.load(f)
    
    stage1_scorer = Stage1Scorer(rule_weight=0.9, graph_weight=0.1)
    
    features = []
    labels = []
    
    print(f"   Feature ì¶”ì¶œ ì¤‘... ({len(data)}ê°œ ìƒ˜í”Œ)")
    for i, item in enumerate(data):
        if (i + 1) % 100 == 0:
            print(f"      {i + 1}/{len(data)} ì²˜ë¦¬ ì¤‘...")
        
        label = item.get("ground_truth_label", "normal")
        labels.append(1 if label == "fraud" else 0)
        
        tx_data = {
            "from": item.get("from", ""),
            "to": item.get("to", ""),
            "usd_value": item.get("usd_value", 0),
            "timestamp": item.get("timestamp", 0),
            "tx_hash": item.get("tx_hash", ""),
            "chain": item.get("chain", "ethereum"),
            "is_sanctioned": item.get("tx_context", {}).get("is_sanctioned", False),
            "is_mixer": item.get("tx_context", {}).get("is_mixer", False),
        }
        
        ml_features = item.get("ml_features", {})
        tx_context = item.get("tx_context", {})
        
        try:
            stage1_result = stage1_scorer.calculate_risk_score(tx_data, ml_features, tx_context)
            feature_vector = extract_enhanced_features(stage1_result, ml_features, tx_context)
            features.append(feature_vector)
        except Exception as e:
            if i < 5:  # ì²˜ìŒ ëª‡ ê°œë§Œ ì—ëŸ¬ ì¶œë ¥
                print(f"      Warning: {e}")
            features.append(np.zeros(40, dtype=np.float32))
    
    return features, labels


def evaluate_model(
    X_train: np.ndarray,
    y_train: np.ndarray,
    X_test: np.ndarray,
    y_test: np.ndarray,
    model,
    model_name: str,
    scaler: StandardScaler
) -> Dict[str, Any]:
    """ëª¨ë¸ í•™ìŠµ ë° í‰ê°€"""
    print(f"\n{'='*80}")
    print(f"{model_name} í‰ê°€ ì¤‘...")
    print(f"{'='*80}")
    
    # ìŠ¤ì¼€ì¼ë§
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # í•™ìŠµ
    print(f"   í•™ìŠµ ì¤‘... (Train: {len(X_train)}ê°œ)")
    model.fit(X_train_scaled, y_train)
    
    # ì˜ˆì¸¡
    print(f"   ì˜ˆì¸¡ ì¤‘... (Test: {len(X_test)}ê°œ)")
    y_pred = model.predict(X_test_scaled)
    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]
    
    # ì„±ëŠ¥ ê³„ì‚°
    acc = accuracy_score(y_test, y_pred)
    prec = precision_score(y_test, y_pred, zero_division=0)
    rec = recall_score(y_test, y_pred, zero_division=0)
    f1 = f1_score(y_test, y_pred, zero_division=0)
    roc = roc_auc_score(y_test, y_pred_proba) if len(set(y_test)) > 1 else 0.5
    
    print(f"   âœ… Accuracy: {acc:.4f} ({acc*100:.2f}%)")
    print(f"   âœ… Precision: {prec:.4f}")
    print(f"   âœ… Recall: {rec:.4f}")
    print(f"   âœ… F1-Score: {f1:.4f}")
    print(f"   âœ… ROC-AUC: {roc:.4f}")
    
    return {
        "model_name": model_name,
        "accuracy": acc,
        "precision": prec,
        "recall": rec,
        "f1_score": f1,
        "roc_auc": roc
    }


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("=" * 80)
    print("ì „ì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì—ì„œ ì£¼ìš” Baseline ëª¨ë¸ í‰ê°€")
    print("=" * 80)
    
    dataset_dir = project_root / "data" / "dataset"
    train_path = dataset_dir / "train.json"
    test_path = dataset_dir / "test.json"
    
    if not train_path.exists() or not test_path.exists():
        print("âŒ ë°ì´í„°ì…‹ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ë°ì´í„° ë¡œë“œ
    print("\nğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘...")
    X_train, y_train = load_dataset(train_path)
    X_test, y_test = load_dataset(test_path)
    
    X_train = np.array(X_train)
    X_test = np.array(X_test)
    y_train = np.array(y_train)
    y_test = np.array(y_test)
    
    print(f"\nğŸ“Š ë°ì´í„°ì…‹ ì •ë³´:")
    print(f"   Train: {len(X_train)}ê°œ, Feature ì°¨ì›: {X_train.shape[1]}")
    print(f"   Test: {len(X_test)}ê°œ")
    print(f"   Train - Fraud: {y_train.sum()}ê°œ ({y_train.sum()/len(y_train)*100:.1f}%)")
    print(f"   Test - Fraud: {y_test.sum()}ê°œ ({y_test.sum()/len(X_test)*100:.1f}%)")
    
    # ìŠ¤ì¼€ì¼ëŸ¬ ì´ˆê¸°í™”
    scaler = StandardScaler()
    
    # ì£¼ìš” ëª¨ë¸ë“¤ í‰ê°€
    results = []
    
    # 1. Logistic Regression (ê°€ì¥ ê°„ë‹¨í•œ baseline)
    results.append(evaluate_model(
        X_train, y_train, X_test, y_test,
        LogisticRegression(max_iter=1000, random_state=42),
        "Logistic Regression",
        StandardScaler()
    ))
    
    # 2. Random Forest
    results.append(evaluate_model(
        X_train, y_train, X_test, y_test,
        RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1),
        "Random Forest",
        StandardScaler()
    ))
    
    # 3. Gradient Boosting
    results.append(evaluate_model(
        X_train, y_train, X_test, y_test,
        GradientBoostingClassifier(n_estimators=100, random_state=42),
        "Gradient Boosting",
        StandardScaler()
    ))
    
    # 4. XGBoost (if available)
    if XGBOOST_AVAILABLE:
        results.append(evaluate_model(
            X_train, y_train, X_test, y_test,
            XGBClassifier(n_estimators=200, max_depth=6, learning_rate=0.1, random_state=42, eval_metric='logloss'),
            "XGBoost",
            StandardScaler()
        ))
    else:
        print("\nâš ï¸  XGBoostë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
    
    # 5. LightGBM (ìµœì‹  ëª¨ë¸)
    if LIGHTGBM_AVAILABLE:
        results.append(evaluate_model(
            X_train, y_train, X_test, y_test,
            LGBMClassifier(n_estimators=200, max_depth=6, learning_rate=0.1, random_state=42, verbose=-1),
            "LightGBM",
            StandardScaler()
        ))
    else:
        print("\nâš ï¸  LightGBMì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
    
    # 6. CatBoost (ìµœì‹  ëª¨ë¸)
    if CATBOOST_AVAILABLE:
        results.append(evaluate_model(
            X_train, y_train, X_test, y_test,
            CatBoostClassifier(iterations=200, depth=6, learning_rate=0.1, random_seed=42, verbose=False),
            "CatBoost",
            StandardScaler()
        ))
    else:
        print("\nâš ï¸  CatBoostë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
    
    # 7. Neural Network (MLP)
    results.append(evaluate_model(
        X_train, y_train, X_test, y_test,
        MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42),
        "Neural Network (MLP)",
        StandardScaler()
    ))
    
    # 8. Stacking Ensemble (ìµœì‹  ì•™ìƒë¸” ê¸°ë²•)
    if XGBOOST_AVAILABLE and LIGHTGBM_AVAILABLE:
        try:
            base_models = [
                ('rf', RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)),
                ('gb', GradientBoostingClassifier(n_estimators=100, random_state=42)),
            ]
            if XGBOOST_AVAILABLE:
                base_models.append(('xgb', XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss')))
            if LIGHTGBM_AVAILABLE:
                base_models.append(('lgbm', LGBMClassifier(n_estimators=100, random_state=42, verbose=-1)))
            
            stacking_model = StackingClassifier(
                estimators=base_models,
                final_estimator=LogisticRegression(max_iter=1000, random_state=42),
                cv=5
            )
            
            results.append(evaluate_model(
                X_train, y_train, X_test, y_test,
                stacking_model,
                "Stacking Ensemble",
                StandardScaler()
            ))
        except Exception as e:
            print(f"\nâš ï¸  Stacking Ensemble ì‹¤íŒ¨: {e}. ê±´ë„ˆëœë‹ˆë‹¤.")
    
    # 9. ì„ í–‰ ì—°êµ¬ ëª¨ë¸ë“¤ (ìœ ì‚¬ êµ¬í˜„)
    print("\n" + "=" * 80)
    print("ì„ í–‰ ì—°êµ¬ ëª¨ë¸ í‰ê°€ (ìœ ì‚¬ êµ¬í˜„)")
    print("=" * 80)
    
    # DeepFD: Deep Learning ê¸°ë°˜ (MLP)
    results.append(evaluate_model(
        X_train, y_train, X_test, y_test,
        MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=42),
        "DeepFD (MLP)",
        StandardScaler()
    ))
    
    # OCGTL: Graph-based (Random Forestë¡œ ìœ ì‚¬ êµ¬í˜„)
    results.append(evaluate_model(
        X_train, y_train, X_test, y_test,
        RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42, class_weight='balanced', n_jobs=-1),
        "OCGTL (RF)",
        StandardScaler()
    ))
    
    # ComGA: Community Detection ê¸°ë°˜ (Gradient Boostingìœ¼ë¡œ ìœ ì‚¬)
    results.append(evaluate_model(
        X_train, y_train, X_test, y_test,
        GradientBoostingClassifier(n_estimators=200, max_depth=10, random_state=42),
        "ComGA (GB)",
        StandardScaler()
    ))
    
    # Flowscope: Flow-based (SVMìœ¼ë¡œ ìœ ì‚¬)
    results.append(evaluate_model(
        X_train, y_train, X_test, y_test,
        SVC(kernel='rbf', probability=True, random_state=42, class_weight='balanced', C=10.0),
        "Flowscope (SVM)",
        StandardScaler()
    ))
    
    # GUDI: Graph Unsupervised (XGBoostë¡œ ìœ ì‚¬)
    if XGBOOST_AVAILABLE:
        results.append(evaluate_model(
            X_train, y_train, X_test, y_test,
            XGBClassifier(n_estimators=200, max_depth=10, random_state=42, eval_metric='logloss'),
            "GUDI (XGB)",
            StandardScaler()
        ))
    
    # MACE: Multi-Attribute (Ensembleë¡œ ìœ ì‚¬)
    try:
        try:
            # sklearn 1.2+ì—ì„œëŠ” estimator íŒŒë¼ë¯¸í„° ì‚¬ìš©
            mace_model = AdaBoostClassifier(
                estimator=RandomForestClassifier(n_estimators=50, max_depth=5, random_state=42, n_jobs=-1),
                n_estimators=50, random_state=42
            )
        except:
            # êµ¬ë²„ì „ í˜¸í™˜
            try:
                mace_model = AdaBoostClassifier(
                    base_estimator=RandomForestClassifier(n_estimators=50, max_depth=5, random_state=42, n_jobs=-1),
                    n_estimators=50, random_state=42
                )
            except:
                # ìµœí›„ì˜ ìˆ˜ë‹¨: ë‹¨ìˆœ AdaBoost
                mace_model = AdaBoostClassifier(n_estimators=100, random_state=42)
        
        results.append(evaluate_model(
            X_train, y_train, X_test, y_test,
            mace_model,
            "MACE (Ensemble)",
            StandardScaler()
        ))
    except Exception as e:
        print(f"\nâš ï¸  MACE (Ensemble) ì‹¤íŒ¨: {e}. ê±´ë„ˆëœë‹ˆë‹¤.")
    
    # 10. Voting Ensemble (ìµœì‹  ì•™ìƒë¸” ê¸°ë²•)
    if XGBOOST_AVAILABLE:
        try:
            voting_models = [
                ('rf', RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)),
                ('gb', GradientBoostingClassifier(n_estimators=100, random_state=42)),
                ('xgb', XGBClassifier(n_estimators=100, random_state=42, eval_metric='logloss')),
            ]
            if LIGHTGBM_AVAILABLE:
                voting_models.append(('lgbm', LGBMClassifier(n_estimators=100, random_state=42, verbose=-1)))
            
            voting_model = VotingClassifier(
                estimators=voting_models,
                voting='soft'
            )
            
            results.append(evaluate_model(
                X_train, y_train, X_test, y_test,
                voting_model,
                "Voting Ensemble",
                StandardScaler()
            ))
        except Exception as e:
            print(f"\nâš ï¸  Voting Ensemble ì‹¤íŒ¨: {e}. ê±´ë„ˆëœë‹ˆë‹¤.")
    
    # 5. ì œì•ˆ ì‹œìŠ¤í…œ (ìµœì í™”ëœ ëª¨ë¸)
    print(f"\n{'='*80}")
    print("ì œì•ˆ ì‹œìŠ¤í…œ (ìµœì í™”ëœ ì•™ìƒë¸” ëª¨ë¸) í‰ê°€ ì¤‘...")
    print(f"{'='*80}")
    
    model_path = project_root / "models" / "improved_stage2_model.pkl"
    if model_path.exists():
        import pickle
        with open(model_path, 'rb') as f:
            model_data = pickle.load(f)
        
        model = model_data['model']
        scaler_loaded = model_data.get('scaler', StandardScaler())
        threshold = model_data.get('threshold', 0.42)
        
        X_test_scaled = scaler_loaded.transform(X_test)
        y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]
        y_pred = (y_pred_proba >= threshold).astype(int)
        
        acc = accuracy_score(y_test, y_pred)
        prec = precision_score(y_test, y_pred, zero_division=0)
        rec = recall_score(y_test, y_pred, zero_division=0)
        f1 = f1_score(y_test, y_pred, zero_division=0)
        roc = roc_auc_score(y_test, y_pred_proba) if len(set(y_test)) > 1 else 0.5
        
        print(f"   âœ… Accuracy: {acc:.4f} ({acc*100:.2f}%)")
        print(f"   âœ… Precision: {prec:.4f}")
        print(f"   âœ… Recall: {rec:.4f}")
        print(f"   âœ… F1-Score: {f1:.4f}")
        print(f"   âœ… ROC-AUC: {roc:.4f}")
        
        results.append({
            "model_name": "ì œì•ˆ ì‹œìŠ¤í…œ (ì•™ìƒë¸”)",
            "accuracy": acc,
            "precision": prec,
            "recall": rec,
            "f1_score": f1,
            "roc_auc": roc
        })
    else:
        print("âš ï¸  ì œì•ˆ ì‹œìŠ¤í…œ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 80)
    print("ìµœì¢… ê²°ê³¼ (ì „ì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ - 752ê°œ ìƒ˜í”Œ)")
    print("=" * 80)
    print(f"{'Model':<30} {'Accuracy':<12} {'Precision':<12} {'Recall':<12} {'F1-Score':<12} {'ROC-AUC':<12}")
    print("-" * 80)
    
    # F1-Score ê¸°ì¤€ ì •ë ¬
    results.sort(key=lambda x: x['f1_score'], reverse=True)
    
    for r in results:
        print(f"{r['model_name']:<30} {r['accuracy']*100:>10.2f}%  {r['precision']:>10.4f}  {r['recall']:>10.4f}  {r['f1_score']:>10.4f}  {r['roc_auc']:>10.4f}")
    
    # ê²°ê³¼ ì €ì¥
    output_path = dataset_dir / "baseline_comparison_full_test.json"
    with open(output_path, 'w') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"\nâœ… ê²°ê³¼ ì €ì¥: {output_path}")


if __name__ == "__main__":
    main()

