#!/usr/bin/env python3
"""
MPOCryptoML ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸

ë…¼ë¬¸ì˜ ë°©ë²•ë¡ ì— ë”°ë¼ MPOCryptoML í”¼ì²˜ë¥¼ ì‚¬ìš©í•˜ì—¬ Logistic Regression ëª¨ë¸ í•™ìŠµ

ì‚¬ìš©ë²•:
    python scripts/train_mpocryptml_model.py
"""
import sys
import json
import pickle
from pathlib import Path
from typing import Dict, List, Any, Tuple
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    roc_auc_score, average_precision_score, confusion_matrix,
    classification_report
)

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))


def extract_features(item: Dict[str, Any]) -> np.ndarray:
    """
    MPOCryptoML í”¼ì²˜ ì¶”ì¶œ
    
    Args:
        item: ë°ì´í„°ì…‹ í•­ëª©
    
    Returns:
        í”¼ì²˜ ë²¡í„° (numpy array)
    """
    ml_features = item.get("ml_features", {})
    
    # ìˆ«ìí˜• í”¼ì²˜ ì¶”ì¶œ
    features = [
        ml_features.get("ppr_score", 0.0),
        ml_features.get("sdn_ppr", 0.0),
        ml_features.get("mixer_ppr", 0.0),
        ml_features.get("pattern_score", 0.0),
        ml_features.get("n_theta", 0.0),
        ml_features.get("n_omega", 0.0),
        ml_features.get("fan_in_count", 0),
        ml_features.get("fan_out_count", 0),
        ml_features.get("gather_scatter", 0.0),
        ml_features.get("graph_nodes", 0),
        ml_features.get("graph_edges", 0),
    ]
    
    # íŒ¨í„´ í”¼ì²˜ (one-hot encoding)
    detected_patterns = ml_features.get("detected_patterns", [])
    pattern_types = ["fan_in", "fan_out", "gather_scatter", "stack", "bipartite"]
    for pattern_type in pattern_types:
        features.append(1.0 if pattern_type in detected_patterns else 0.0)
    
    # Rule-based ì ìˆ˜ë„ í”¼ì²˜ë¡œ í¬í•¨ (ì„ íƒì )
    rule_score = item.get("rule_score", 0.0)
    features.append(rule_score)
    
    return np.array(features, dtype=np.float32)


def load_dataset(file_path: Path) -> Tuple[List[np.ndarray], List[int]]:
    """
    ë°ì´í„°ì…‹ ë¡œë“œ ë° í”¼ì²˜/ë¼ë²¨ ì¶”ì¶œ
    
    Args:
        file_path: ë°ì´í„°ì…‹ JSON íŒŒì¼ ê²½ë¡œ
    
    Returns:
        (features, labels) íŠœí”Œ
    """
    with open(file_path, 'r') as f:
        data = json.load(f)
    
    features = []
    labels = []
    
    for item in data:
        # í”¼ì²˜ ì¶”ì¶œ
        feature_vector = extract_features(item)
        features.append(feature_vector)
        
        # ë¼ë²¨ ë³€í™˜ (fraud=1, normal=0)
        label = item.get("ground_truth_label", "normal")
        labels.append(1 if label == "fraud" else 0)
    
    return features, labels


def train_mpocryptml_model(
    train_path: Path,
    val_path: Path,
    output_path: Path
) -> Dict[str, Any]:
    """
    MPOCryptoML ëª¨ë¸ í•™ìŠµ
    
    Args:
        train_path: í•™ìŠµ ë°ì´í„°ì…‹ ê²½ë¡œ
        val_path: ê²€ì¦ ë°ì´í„°ì…‹ ê²½ë¡œ
        output_path: ëª¨ë¸ ì €ì¥ ê²½ë¡œ
    
    Returns:
        í•™ìŠµ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    print("=" * 60)
    print("MPOCryptoML ëª¨ë¸ í•™ìŠµ")
    print("=" * 60)
    
    # ë°ì´í„° ë¡œë“œ
    print("\nğŸ“‚ ë°ì´í„° ë¡œë“œ ì¤‘...")
    X_train, y_train = load_dataset(train_path)
    X_val, y_val = load_dataset(val_path)
    
    X_train = np.array(X_train)
    X_val = np.array(X_val)
    y_train = np.array(y_train)
    y_val = np.array(y_val)
    
    print(f"   í•™ìŠµ ë°ì´í„°: {len(X_train)}ê°œ")
    print(f"   ê²€ì¦ ë°ì´í„°: {len(X_val)}ê°œ")
    print(f"   í”¼ì²˜ ì°¨ì›: {X_train.shape[1]}ê°œ")
    
    # í”¼ì²˜ ìŠ¤ì¼€ì¼ë§
    print("\nğŸ”§ í”¼ì²˜ ìŠ¤ì¼€ì¼ë§ ì¤‘...")
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_val_scaled = scaler.transform(X_val)
    
    # ëª¨ë¸ í•™ìŠµ
    print("\nğŸ¯ ëª¨ë¸ í•™ìŠµ ì¤‘...")
    model = LogisticRegression(
        max_iter=1000,
        random_state=42,
        class_weight='balanced'  # ë¶ˆê· í˜• ë°ì´í„° ì²˜ë¦¬
    )
    
    model.fit(X_train_scaled, y_train)
    
    # ê²€ì¦ ë°ì´í„° ì˜ˆì¸¡
    y_pred = model.predict(X_val_scaled)
    y_pred_proba = model.predict_proba(X_val_scaled)[:, 1]
    
    # í‰ê°€ ì§€í‘œ ê³„ì‚°
    accuracy = accuracy_score(y_val, y_pred)
    precision = precision_score(y_val, y_pred, zero_division=0)
    recall = recall_score(y_val, y_pred, zero_division=0)
    f1 = f1_score(y_val, y_pred, zero_division=0)
    
    try:
        roc_auc = roc_auc_score(y_val, y_pred_proba) if len(set(y_pred_proba)) > 1 else 0.5
        avg_precision = average_precision_score(y_val, y_pred_proba)
    except:
        roc_auc = 0.5
        avg_precision = 0.0
    
    cm = confusion_matrix(y_val, y_pred)
    
    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 60)
    print("âœ… í•™ìŠµ ì™„ë£Œ!")
    print("=" * 60)
    print(f"\nğŸ“Š ê²€ì¦ ì„±ëŠ¥:")
    print(f"   Accuracy:  {accuracy:.4f} ({accuracy*100:.2f}%)")
    print(f"   Precision: {precision:.4f}")
    print(f"   Recall:    {recall:.4f}")
    print(f"   F1-Score:  {f1:.4f}")
    print(f"   ROC-AUC:   {roc_auc:.4f}")
    print(f"   Avg Precision: {avg_precision:.4f}")
    
    print(f"\nğŸ“ˆ Confusion Matrix:")
    print(f"   True Negative:  {cm[0][0]}")
    print(f"   False Positive: {cm[0][1]}")
    print(f"   False Negative: {cm[1][0]}")
    print(f"   True Positive:  {cm[1][1]}")
    
    # ëª¨ë¸ ì €ì¥
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    model_data = {
        "model": model,
        "scaler": scaler,
        "feature_names": [
            "ppr_score", "sdn_ppr", "mixer_ppr", "pattern_score",
            "n_theta", "n_omega", "fan_in_count", "fan_out_count",
            "gather_scatter", "graph_nodes", "graph_edges",
            "pattern_fan_in", "pattern_fan_out", "pattern_gather_scatter",
            "pattern_stack", "pattern_bipartite", "rule_score"
        ]
    }
    
    with open(output_path, 'wb') as f:
        pickle.dump(model_data, f)
    
    print(f"\nğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {output_path}")
    
    # í•™ìŠµ ê²°ê³¼ ë°˜í™˜
    results = {
        "accuracy": float(accuracy),
        "precision": float(precision),
        "recall": float(recall),
        "f1_score": float(f1),
        "roc_auc": float(roc_auc),
        "average_precision": float(avg_precision),
        "confusion_matrix": {
            "true_negative": int(cm[0][0]),
            "false_positive": int(cm[0][1]),
            "false_negative": int(cm[1][0]),
            "true_positive": int(cm[1][1])
        }
    }
    
    return results


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    dataset_dir = project_root / "data" / "dataset"
    train_path = dataset_dir / "train.json"
    val_path = dataset_dir / "val.json"
    model_path = project_root / "models" / "mpocryptml_model.pkl"
    
    if not train_path.exists():
        print(f"âŒ í•™ìŠµ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {train_path}")
        return
    
    if not val_path.exists():
        print(f"âŒ ê²€ì¦ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {val_path}")
        return
    
    # ëª¨ë¸ í•™ìŠµ
    results = train_mpocryptml_model(train_path, val_path, model_path)
    
    # ê²°ê³¼ ì €ì¥
    results_path = dataset_dir / "mpocryptml_training_results.json"
    with open(results_path, 'w') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“„ í•™ìŠµ ê²°ê³¼ ì €ì¥: {results_path}")
    print("\në‹¤ìŒ ë‹¨ê³„:")
    print("1. ëª¨ë¸ í‰ê°€: python scripts/evaluate_mpocryptml_model.py")
    print("2. Hybrid ëª¨ë¸ í•™ìŠµ (Rule-based + MPOCryptoML)")


if __name__ == "__main__":
    main()

