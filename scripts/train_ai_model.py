#!/usr/bin/env python3
"""
AI ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸

ì‚¬ìš©ë²•:
    python scripts/train_ai_model.py
"""
import json
import sys
from pathlib import Path
import pickle

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from core.scoring.ai_weight_learner import RuleWeightLearner


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # í•™ìŠµ ë°ì´í„° ë¡œë“œ
    train_path = project_root / "data" / "dataset" / "train.json"
    if not train_path.exists():
        print(f"âŒ í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤: {train_path}")
        print("   ë¨¼ì € ë°ì´í„°ì…‹ì„ ë¶„í• í•˜ì„¸ìš”: python scripts/split_dataset.py")
        return
    
    print(f"ğŸ“‚ í•™ìŠµ ë°ì´í„° ë¡œë“œ: {train_path.name}")
    
    try:
        with open(train_path, 'r') as f:
            train_data = json.load(f)
    except Exception as e:
        print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        return
    
    if not train_data:
        print("âŒ í•™ìŠµ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        return
    
    print(f"ğŸ“Š í•™ìŠµ ìƒ˜í”Œ: {len(train_data)}ê°œ")
    
    # ë°ì´í„° í˜•ì‹ ë³€í™˜
    print("\në°ì´í„° í˜•ì‹ ë³€í™˜ ì¤‘...")
    training_data = []
    
    for item in train_data:
        rule_results = item.get("rule_results", [])
        actual_score = item.get("actual_risk_score", 0.0)
        tx_context = item.get("tx_context", {})
        
        training_data.append((rule_results, actual_score, tx_context))
    
    print(f"âœ… {len(training_data)}ê°œ ìƒ˜í”Œ ì¤€ë¹„ ì™„ë£Œ")
    
    # ëª¨ë¸ í•™ìŠµ
    print("\nğŸ¤– AI ëª¨ë¸ í•™ìŠµ ì‹œì‘...")
    print("   (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
    
    try:
        learner = RuleWeightLearner(use_ai=True)
        learner.train(training_data)
        
        # ëª¨ë¸ ì €ì¥
        model_dir = project_root / "models"
        model_dir.mkdir(exist_ok=True)
        
        model_path = model_dir / "rule_weights.pkl"
        with open(model_path, 'wb') as f:
            pickle.dump({
                'model': learner.model,
                'scaler': learner.scaler,
                'rule_features': learner.rule_features,
                'rule_based_weights': learner.rule_based_weights
            }, f)
        
        print(f"\nâœ… í•™ìŠµ ì™„ë£Œ!")
        print(f"   ëª¨ë¸ ì €ì¥: {model_path}")
        
    except ImportError:
        print("\nâš ï¸  scikit-learnì´ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("   ê·œì¹™ ê¸°ë°˜ ê°€ì¤‘ì¹˜ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        print("\n   ì„¤ì¹˜: pip install scikit-learn")
        
        # ê·œì¹™ ê¸°ë°˜ ê°€ì¤‘ì¹˜ë§Œ ì €ì¥
        learner = RuleWeightLearner(use_ai=False)
        model_dir = project_root / "models"
        model_dir.mkdir(exist_ok=True)
        
        model_path = model_dir / "rule_weights_rule_based.pkl"
        with open(model_path, 'wb') as f:
            pickle.dump({
                'rule_based_weights': learner.rule_based_weights,
                'use_ai': False
            }, f)
        
        print(f"   ê·œì¹™ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ì €ì¥: {model_path}")
    
    except Exception as e:
        print(f"\nâŒ í•™ìŠµ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()

