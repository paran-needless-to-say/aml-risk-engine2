# AI ì‘ì—… ê´€ë¦¬ ê°€ì´ë“œ

ë°ì´í„° ìˆ˜ì§‘ ì¤‘ì—ë„ AI ê´€ë ¨ ì‘ì—…ì„ ì§„í–‰í•  ìˆ˜ ìˆë„ë¡ ì •ë¦¬í•œ ê°€ì´ë“œì…ë‹ˆë‹¤.

---

## ğŸ“Š í˜„ì¬ ìƒíƒœ

### âœ… êµ¬í˜„ ì™„ë£Œ

1. **AI ê¸°ë°˜ ê°€ì¤‘ì¹˜ í•™ìŠµ ëª¨ë“ˆ** (`core/scoring/ai_weight_learner.py`)

   - ê·œì¹™ ê¸°ë°˜ ê°€ì¤‘ì¹˜ (ì¦‰ì‹œ ì‚¬ìš© ê°€ëŠ¥)
   - AI ëª¨ë¸ í•™ìŠµ ê¸°ëŠ¥ (ë°ì´í„° í•„ìš”)
   - ë£° íŠ¹ì„± ë°˜ì˜ (axis, severity, pattern type)

2. **ë°ì´í„°ì…‹ êµ¬ì¶• ëª¨ë“ˆ** (`core/scoring/dataset_builder.py`)

   - Demo ë°ì´í„° í™œìš©
   - ë ˆê±°ì‹œ ë°ì´í„° í™œìš©
   - ê·œì¹™ ê¸°ë°˜ ìë™ ë¼ë²¨ë§

3. **ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘** (`core/scoring/real_dataset_builder.py`)
   - Etherscan API V2 ì—°ë™
   - ìë™ íƒœê·¸ ì •ë³´ ì¡°íšŒ
   - ìë™ ë¼ë²¨ë§

---

## ğŸ¯ ë‹¤ìŒ ë‹¨ê³„ ì‘ì—…

### 1. ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ ëŒ€ê¸° (í˜„ì¬ ì§„í–‰ ì¤‘)

**ìƒíƒœ í™•ì¸**:

```bash
# ì§„í–‰ ìƒí™© í™•ì¸
cat logs/collection_progress.json

# ë¡œê·¸ í™•ì¸
tail -f logs/collect.log
```

**ì˜ˆìƒ ì‹œê°„**: 10-30ë¶„ (ì£¼ì†Œ ìˆ˜ì— ë”°ë¼)

---

### 2. ë°ì´í„°ì…‹ ë¶„í•  (ìˆ˜ì§‘ ì™„ë£Œ í›„)

**ëª©ì **: í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ìœ¼ë¡œ ë¶„í• 

**êµ¬í˜„ í•„ìš”**:

```python
# scripts/split_dataset.py
from core.scoring.dataset_builder import DatasetBuilder
import json

builder = DatasetBuilder()

# ë°ì´í„°ì…‹ ë¡œë“œ
with open("data/dataset/real_high_risk.json", 'r') as f:
    dataset = json.load(f)

# ë¶„í• 
train, val, test = builder.split_dataset(
    dataset,
    train_ratio=0.7,
    val_ratio=0.15,
    test_ratio=0.15,
    stratify=True
)

# ì €ì¥
with open("data/dataset/train.json", 'w') as f:
    json.dump(train, f, indent=2)
with open("data/dataset/val.json", 'w') as f:
    json.dump(val, f, indent=2)
with open("data/dataset/test.json", 'w') as f:
    json.dump(test, f, indent=2)
```

---

### 3. AI ëª¨ë¸ í•™ìŠµ (ë°ì´í„°ì…‹ ì¤€ë¹„ í›„)

**í˜„ì¬ ìƒíƒœ**: ëª¨ë“ˆì€ êµ¬í˜„ë˜ì–´ ìˆìœ¼ë‚˜ í•™ìŠµ ë°ì´í„° í•„ìš”

**í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± í•„ìš”**:

```python
# scripts/train_ai_model.py
from core.scoring.ai_weight_learner import RuleWeightLearner
import json

# í•™ìŠµ ë°ì´í„° ë¡œë“œ
with open("data/dataset/train.json", 'r') as f:
    train_data = json.load(f)

# ë°ì´í„° í˜•ì‹ ë³€í™˜
training_data = [
    (
        item["rule_results"],
        item["actual_risk_score"],
        item.get("tx_context", {})
    )
    for item in train_data
]

# ëª¨ë¸ í•™ìŠµ
learner = RuleWeightLearner(use_ai=True)
learner.train(training_data)

# ëª¨ë¸ ì €ì¥
learner.save_model("models/rule_weights.pkl")
```

---

### 4. ëª¨ë¸ í‰ê°€ (í•™ìŠµ ì™„ë£Œ í›„)

**í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± í•„ìš”**:

```python
# scripts/evaluate_model.py
from core.scoring.ai_weight_learner import RuleWeightLearner
import json

# ëª¨ë¸ ë¡œë“œ
learner = RuleWeightLearner(use_ai=True)
learner.load_model("models/rule_weights.pkl")

# í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
with open("data/dataset/test.json", 'r') as f:
    test_data = json.load(f)

# í‰ê°€
# ... í‰ê°€ ë¡œì§
```

---

## ğŸ”§ ì§€ê¸ˆ í•  ìˆ˜ ìˆëŠ” ì‘ì—…

### 1. ë°ì´í„°ì…‹ ë¶„í•  ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±

```bash
# ìƒˆ íŒŒì¼ ìƒì„±
touch scripts/split_dataset.py
```

**êµ¬í˜„ ë‚´ìš©**:

- ë°ì´í„°ì…‹ ë¡œë“œ
- í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸ ë¶„í• 
- í†µê³„ ì¶œë ¥
- ì €ì¥

---

### 2. AI ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±

```bash
# ìƒˆ íŒŒì¼ ìƒì„±
touch scripts/train_ai_model.py
```

**êµ¬í˜„ ë‚´ìš©**:

- í•™ìŠµ ë°ì´í„° ë¡œë“œ
- ë°ì´í„° í˜•ì‹ ë³€í™˜
- ëª¨ë¸ í•™ìŠµ
- ëª¨ë¸ ì €ì¥

---

### 3. ëª¨ë¸ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±

```bash
# ìƒˆ íŒŒì¼ ìƒì„±
touch scripts/evaluate_model.py
```

**êµ¬í˜„ ë‚´ìš©**:

- ëª¨ë¸ ë¡œë“œ
- í…ŒìŠ¤íŠ¸ ë°ì´í„° í‰ê°€
- ë©”íŠ¸ë¦­ ê³„ì‚° (Accuracy, F1, Precision, Recall)
- ê²°ê³¼ ì¶œë ¥

---

### 4. ë¬¸ì„œ ì •ë¦¬

- AI ê°€ì¤‘ì¹˜ í•™ìŠµ ê°€ì´ë“œ ì—…ë°ì´íŠ¸
- ë°ì´í„°ì…‹ êµ¬ì¶• ê°€ì´ë“œ ì—…ë°ì´íŠ¸
- ì „ì²´ ì›Œí¬í”Œë¡œìš° ë¬¸ì„œí™”

---

## ğŸ“‹ ì‘ì—… ì²´í¬ë¦¬ìŠ¤íŠ¸

### ì¦‰ì‹œ ê°€ëŠ¥ (ë°ì´í„° ìˆ˜ì§‘ ëŒ€ê¸° ì¤‘)

- [ ] ë°ì´í„°ì…‹ ë¶„í•  ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
- [ ] AI ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
- [ ] ëª¨ë¸ í‰ê°€ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
- [ ] ë¬¸ì„œ ì •ë¦¬ ë° ì—…ë°ì´íŠ¸

### ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ í›„

- [ ] ë°ì´í„°ì…‹ ë¶„í•  ì‹¤í–‰
- [ ] ë°ì´í„°ì…‹ í†µê³„ í™•ì¸
- [ ] AI ëª¨ë¸ í•™ìŠµ ì‹¤í–‰
- [ ] ëª¨ë¸ í‰ê°€ ì‹¤í–‰
- [ ] ê²°ê³¼ ë¶„ì„

---

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. ë°ì´í„°ì…‹ ë¶„í•  ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±

```python
# scripts/split_dataset.py
from core.scoring.dataset_builder import DatasetBuilder
import json
from pathlib import Path

def main():
    builder = DatasetBuilder()

    # ë°ì´í„°ì…‹ ë¡œë“œ
    dataset_path = Path("data/dataset/real_high_risk.json")
    if not dataset_path.exists():
        print(f"ë°ì´í„°ì…‹ì´ ì—†ìŠµë‹ˆë‹¤: {dataset_path}")
        return

    with open(dataset_path, 'r') as f:
        dataset = json.load(f)

    print(f"ì´ {len(dataset)}ê°œ ìƒ˜í”Œ")

    # ë¶„í• 
    train, val, test = builder.split_dataset(
        dataset,
        train_ratio=0.7,
        val_ratio=0.15,
        test_ratio=0.15,
        stratify=True
    )

    # ì €ì¥
    output_dir = Path("data/dataset")
    output_dir.mkdir(parents=True, exist_ok=True)

    with open(output_dir / "train.json", 'w') as f:
        json.dump(train, f, indent=2)
    with open(output_dir / "val.json", 'w') as f:
        json.dump(val, f, indent=2)
    with open(output_dir / "test.json", 'w') as f:
        json.dump(test, f, indent=2)

    print(f"\nâœ… ë¶„í•  ì™„ë£Œ:")
    print(f"   í•™ìŠµ: {len(train)}ê°œ")
    print(f"   ê²€ì¦: {len(val)}ê°œ")
    print(f"   í…ŒìŠ¤íŠ¸: {len(test)}ê°œ")

if __name__ == "__main__":
    main()
```

---

### 2. AI ëª¨ë¸ í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±

```python
# scripts/train_ai_model.py
from core.scoring.ai_weight_learner import RuleWeightLearner
import json
from pathlib import Path

def main():
    # í•™ìŠµ ë°ì´í„° ë¡œë“œ
    train_path = Path("data/dataset/train.json")
    if not train_path.exists():
        print(f"í•™ìŠµ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤: {train_path}")
        return

    with open(train_path, 'r') as f:
        train_data = json.load(f)

    print(f"í•™ìŠµ ë°ì´í„°: {len(train_data)}ê°œ")

    # ë°ì´í„° í˜•ì‹ ë³€í™˜
    training_data = [
        (
            item["rule_results"],
            item["actual_risk_score"],
            item.get("tx_context", {})
        )
        for item in train_data
    ]

    # ëª¨ë¸ í•™ìŠµ
    print("\nëª¨ë¸ í•™ìŠµ ì‹œì‘...")
    learner = RuleWeightLearner(use_ai=True)
    learner.train(training_data)

    # ëª¨ë¸ ì €ì¥
    model_dir = Path("models")
    model_dir.mkdir(exist_ok=True)

    # TODO: save_model ë©”ì„œë“œ êµ¬í˜„ í•„ìš”
    # learner.save_model(model_dir / "rule_weights.pkl")

    print("âœ… í•™ìŠµ ì™„ë£Œ!")

if __name__ == "__main__":
    main()
```

---

## ğŸ’¡ í˜„ì¬ í•  ìˆ˜ ìˆëŠ” ì‘ì—… ìš°ì„ ìˆœìœ„

### 1ìˆœìœ„: ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± (ì¦‰ì‹œ ê°€ëŠ¥)

1. `scripts/split_dataset.py` - ë°ì´í„°ì…‹ ë¶„í• 
2. `scripts/train_ai_model.py` - ëª¨ë¸ í•™ìŠµ
3. `scripts/evaluate_model.py` - ëª¨ë¸ í‰ê°€

### 2ìˆœìœ„: ë¬¸ì„œ ì •ë¦¬

1. ì „ì²´ ì›Œí¬í”Œë¡œìš° ë¬¸ì„œí™”
2. AI í•™ìŠµ ê°€ì´ë“œ ì—…ë°ì´íŠ¸
3. ì‚¬ìš© ì˜ˆì‹œ ì¶”ê°€

### 3ìˆœìœ„: ê¸°ëŠ¥ ê°œì„ 

1. ëª¨ë¸ ì €ì¥/ë¡œë“œ ê¸°ëŠ¥ ì¶”ê°€
2. í‰ê°€ ë©”íŠ¸ë¦­ ê³„ì‚°
3. ê²°ê³¼ ì‹œê°í™”

---

## ğŸ”— ê´€ë ¨ íŒŒì¼

- `core/scoring/ai_weight_learner.py`: AI ê°€ì¤‘ì¹˜ í•™ìŠµ ëª¨ë“ˆ
- `core/scoring/dataset_builder.py`: ë°ì´í„°ì…‹ êµ¬ì¶• ëª¨ë“ˆ
- `core/scoring/real_dataset_builder.py`: ì‹¤ì œ ë°ì´í„° ìˆ˜ì§‘
- `docs/AI_WEIGHT_LEARNING.md`: AI í•™ìŠµ ê°€ì´ë“œ
- `docs/DATASET_BUILDING_GUIDE.md`: ë°ì´í„°ì…‹ êµ¬ì¶• ê°€ì´ë“œ

---

## ğŸ“ ë‹¤ìŒ ì‘ì—… ì œì•ˆ

ë°ì´í„° ìˆ˜ì§‘ì´ ì™„ë£Œë˜ë©´:

1. **ë°ì´í„°ì…‹ ë¶„í• ** â†’ í•™ìŠµ/ê²€ì¦/í…ŒìŠ¤íŠ¸
2. **AI ëª¨ë¸ í•™ìŠµ** â†’ ì‹¤ì œ ë°ì´í„°ë¡œ ê°€ì¤‘ì¹˜ í•™ìŠµ
3. **ëª¨ë¸ í‰ê°€** â†’ ì„±ëŠ¥ í™•ì¸
4. **í”„ë¡œë•ì…˜ ì ìš©** â†’ í•™ìŠµëœ ëª¨ë¸ ì‚¬ìš©

ì§€ê¸ˆì€ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ë¯¸ë¦¬ ì‘ì„±í•´ë‘ë©´ ìˆ˜ì§‘ ì™„ë£Œ í›„ ë°”ë¡œ ì§„í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!
